"""
Shared utilities for the IB-bench evaluation pipeline.
"""

import hashlib
import json
import os
import re
import time
from dataclasses import dataclass
from datetime import datetime
from functools import wraps
from pathlib import Path

import yaml
from dotenv import load_dotenv

load_dotenv(Path(__file__).parent.parent / ".env")


class JudgeParseError(Exception):
    def __init__(self, message: str, raw_response: str = ""):
        super().__init__(message)
        self.raw_response = raw_response


def retry_on_rate_limit(max_retries: int = 3, initial_wait: int = 60):
    """Decorator to retry on rate limit errors with exponential backoff.

    Args:
        max_retries: Maximum number of retry attempts
        initial_wait: Initial wait time in seconds (doubles each retry)
    """

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            wait_time = initial_wait

            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    error_str = str(e)
                    # Check if it's a rate limit error (429)
                    if "429" in error_str or "rate_limit" in error_str.lower():
                        last_exception = e
                        if attempt < max_retries:
                            print(
                                f"  Rate limited. Waiting {wait_time}s before retry ({attempt + 1}/{max_retries})..."
                            )
                            time.sleep(wait_time)
                            wait_time *= 2  # Exponential backoff
                        else:
                            print(
                                f"  Rate limited. Max retries ({max_retries}) exceeded."
                            )
                            raise
                    else:
                        # Not a rate limit error, raise immediately
                        raise

            raise last_exception

        return wrapper

    return decorator


@dataclass
class Task:
    """Represents a SINGLE evaluation task."""

    id: str
    task_dir: Path
    task_type: str
    category: str
    description: str
    prompt: str
    rubric: dict
    input_files: list[Path]


@dataclass
class OutputFile:
    """A file generated by the LLM (e.g., from code execution)."""

    filename: str
    content: bytes
    mime_type: str = "application/octet-stream"


@dataclass
class LLMResponse:
    """Standardized response from any LLM provider."""

    raw_text: str
    parsed_json: dict | None
    model: str
    input_tokens: int
    output_tokens: int
    latency_ms: float
    stop_reason: str = "unknown"  # end_turn, max_tokens, stop_sequence, tool_use, etc.
    output_files: list[OutputFile] | None = None  # Files generated by code execution


def load_task(task_dir: Path, include_rubric: bool = True) -> Task:
    """Load a single task from a directory."""
    # Parse meta.yaml
    meta_path = task_dir / "meta.yaml"
    with open(meta_path) as f:
        meta = yaml.safe_load(f)

    # Skip if meta.yaml is not a proper dict (e.g., just a comment blurb)
    if not isinstance(meta, dict):
        raise ValueError(
            f"meta.yaml is not a valid task definition (got {type(meta).__name__})"
        )

    task_meta = meta.get("task", {})

    # Read prompt
    prompt_path = task_dir / "prompt.md"
    prompt = prompt_path.read_text()

    # Read rubric (only if needed for scoring)
    rubric = {}
    if include_rubric:
        rubric_path = task_dir / "rubric.json"
        if rubric_path.exists():
            with open(rubric_path) as f:
                rubric = json.load(f)

    # Find input files (glob pattern: input*.*)
    input_files = list(task_dir.glob("input*.*"))

    return Task(
        id=task_meta.get("id"),
        task_dir=task_dir,
        task_type=task_meta.get("type"),
        category=task_meta.get("category"),
        description=task_meta.get("description", ""),
        prompt=prompt,
        rubric=rubric,
        input_files=input_files,
    )


def load_tasks(
    tasks_dir: Path | None = None,
    task_ids: list[str] | None = None,
    filter_pattern: str | None = None,
    include_rubric: bool = True,
) -> list[Task]:
    """Discover and load tasks from the tasks directory.

    Args:
        tasks_dir: Path to tasks directory. Defaults to eval/tasks/
        task_ids: Optional list of specific task IDs to load (e.g., ["e-001"])
        filter_pattern: Optional prefix filter (e.g., "e-" for easy tasks)
        include_rubric: Whether to load rubric.json (only needed for scoring)

    Returns:
        List of Task objects.
    """
    if tasks_dir is None:
        tasks_dir = Path(__file__).parent / "tasks"

    tasks = []

    for task_path in sorted(tasks_dir.iterdir()):
        if not task_path.is_dir():
            continue

        task_id = task_path.name

        # Filter by task_ids if provided
        if task_ids and task_id not in task_ids:
            continue

        # Filter by pattern if provided
        if filter_pattern and not task_id.startswith(filter_pattern):
            continue

        try:
            task = load_task(task_path, include_rubric=include_rubric)
            tasks.append(task)
        except (FileNotFoundError, ValueError) as e:
            print(f"Warning: Skipping {task_path.name}: {e}")

    return tasks


def get_rubric_hash(rubric: dict) -> str:
    """Generate 8-char hash of rubric content for versioning."""
    content = json.dumps(rubric, sort_keys=True)
    return hashlib.sha256(content.encode()).hexdigest()[:8]


def _extract_json(text: str) -> dict | None:
    """Extract JSON object from response text."""
    # Try direct parse first
    try:
        return json.loads(text.strip())
    except json.JSONDecodeError:
        pass

    # Try to find JSON in code blocks
    json_match = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(1))
        except json.JSONDecodeError:
            pass

    # Try to find raw JSON object
    json_match = re.search(r"\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}", text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(0))
        except json.JSONDecodeError:
            pass

    return None


class AnthropicRunner:
    """Run tasks against Anthropic Claude models with code execution for Excel files."""

    def __init__(self, api_key: str | None = None, model: str | None = None):
        if not model:
            raise ValueError("model is required for AnthropicRunner")
        self.api_key = api_key or os.environ.get("ANTHROPIC_API_KEY")
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not set")
        self.model = model
        self._client = None

    @property
    def client(self):
        if self._client is None:
            import anthropic

            self._client = anthropic.Anthropic(api_key=self.api_key)
        return self._client

    @retry_on_rate_limit(max_retries=3, initial_wait=60)
    def run(self, task: Task, input_files: list[Path] | None = None) -> LLMResponse:
        """Execute a task against Claude with file upload via Files API."""
        files = input_files or []
        if files:
            return self._run_with_files(task, files)
        else:
            return self._run_text_only(task)

    def _run_text_only(self, task: Task) -> LLMResponse:
        """Run task with text prompt only (no Excel file)."""
        start = time.time()
        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=16384,
                temperature=0,  # Deterministic for reproducible evals
                messages=[{"role": "user", "content": task.prompt}],
            )
        except Exception as e:
            latency_ms = (time.time() - start) * 1000
            error_str = str(e).lower()
            # Check for content filter / policy violation errors
            if "content" in error_str and (
                "policy" in error_str or "blocked" in error_str or "safety" in error_str
            ):
                print(f"  BLOCKED: Content filter triggered")
                return LLMResponse(
                    raw_text="",
                    parsed_json=None,
                    model=self.model,
                    input_tokens=0,
                    output_tokens=0,
                    latency_ms=latency_ms,
                    stop_reason="content_filter",
                    output_files=None,
                )
            raise

        latency_ms = (time.time() - start) * 1000

        raw_text = response.content[0].text
        parsed_json = _extract_json(raw_text)
        stop_reason = response.stop_reason or "unknown"

        if stop_reason == "max_tokens":
            print(f"  WARNING: Output truncated (hit max_tokens limit)")

        return LLMResponse(
            raw_text=raw_text,
            parsed_json=parsed_json,
            model=self.model,
            input_tokens=response.usage.input_tokens,
            output_tokens=response.usage.output_tokens,
            latency_ms=latency_ms,
            stop_reason=stop_reason,
            output_files=None,
        )

    def _run_with_files(self, task: Task, input_files: list[Path]) -> LLMResponse:
        """Run with file upload - uploads files via Files API and uses code execution."""
        # Upload all files
        file_ids = []
        for input_file in input_files:
            print(f"  Uploading {input_file.name} to Files API...")
            with open(input_file, "rb") as f:
                file_obj = self.client.beta.files.upload(file=f)
                file_ids.append(file_obj.id)

        # Build message with file references
        content = []
        for file_id in file_ids:
            content.append({"type": "container_upload", "file_id": file_id})
        content.append({"type": "text", "text": task.prompt})

        # Call with code execution tool
        start = time.time()
        content_filter_triggered = False
        try:
            response = self.client.beta.messages.create(
                model=self.model,
                betas=["code-execution-2025-08-25", "files-api-2025-04-14"],
                max_tokens=16384,
                temperature=0,  # Deterministic for reproducible evals
                messages=[{"role": "user", "content": content}],
                tools=[{"type": "code_execution_20250825", "name": "code_execution"}],
            )
        except Exception as e:
            error_str = str(e).lower()
            # Check for content filter / policy violation errors
            if "content" in error_str and (
                "policy" in error_str or "blocked" in error_str or "safety" in error_str
            ):
                print(f"  BLOCKED: Content filter triggered")
                content_filter_triggered = True
                response = None
            else:
                raise
        finally:
            # Cleanup uploaded files
            for file_id in file_ids:
                try:
                    self.client.beta.files.delete(file_id)
                except Exception as e:
                    print(f"  Warning: Failed to delete file {file_id}: {e}")

        latency_ms = (time.time() - start) * 1000

        # Return early if content filter was triggered
        if content_filter_triggered:
            return LLMResponse(
                raw_text="",
                parsed_json=None,
                model=self.model,
                input_tokens=0,
                output_tokens=0,
                latency_ms=latency_ms,
                stop_reason="content_filter",
                output_files=None,
            )

        # Extract text and files from response (may have multiple content blocks)
        raw_text = ""
        output_files = []
        container_id = None

        for block in response.content:
            if hasattr(block, "text"):
                raw_text += block.text + "\n"
            # Check for code execution result with container and stdout
            if hasattr(block, "type") and block.type == "code_execution_result":
                if hasattr(block, "container_id"):
                    container_id = block.container_id
                # Extract stdout from code execution (may contain JSON output)
                if hasattr(block, "content"):
                    for item in block.content:
                        if hasattr(item, "stdout") and item.stdout:
                            raw_text += item.stdout + "\n"
                        elif hasattr(item, "text") and item.text:
                            raw_text += item.text + "\n"

        # If there's a container, check for output files
        if container_id:
            try:
                # List files in the container
                container_files = self.client.beta.files.list(container_id=container_id)
                for cf in container_files.data:
                    # Download each file
                    print(f"  Downloading output file: {cf.filename}")
                    file_content = self.client.beta.files.download(cf.id)
                    output_files.append(
                        OutputFile(
                            filename=cf.filename,
                            content=file_content.read()
                            if hasattr(file_content, "read")
                            else file_content,
                            mime_type=getattr(
                                cf, "mime_type", "application/octet-stream"
                            ),
                        )
                    )
            except Exception as e:
                print(f"  Warning: Failed to retrieve container files: {e}")

        parsed_json = _extract_json(raw_text)
        stop_reason = response.stop_reason or "unknown"

        if stop_reason == "max_tokens":
            print(f"  WARNING: Output truncated (hit max_tokens limit)")

        return LLMResponse(
            raw_text=raw_text,
            parsed_json=parsed_json,
            model=self.model,
            input_tokens=response.usage.input_tokens,
            output_tokens=response.usage.output_tokens,
            latency_ms=latency_ms,
            stop_reason=stop_reason,
            output_files=output_files if output_files else None,
        )


class OpenAIRunner:
    """Run tasks against OpenAI models using Responses API.

    Migrated from Assistants API (deprecated Aug 2026) to Responses API.
    See: https://platform.openai.com/docs/guides/migrate-to-responses
    """

    def __init__(self, api_key: str | None = None, model: str | None = None):
        if not model:
            raise ValueError("model is required for OpenAIRunner")
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not set")
        self.model = model
        self._client = None

    @property
    def client(self):
        if self._client is None:
            import openai

            self._client = openai.OpenAI(api_key=self.api_key)
        return self._client

    def _upload_file(self, path: Path) -> str:
        """Upload file to OpenAI Files API for use with Responses API."""
        with open(path, "rb") as f:
            file = self.client.files.create(file=f, purpose="user_data")
        return file.id

    def _create_vector_store(self, file_ids: list[str]) -> str:
        """Create a vector store with uploaded files for file_search."""
        vs = self.client.vector_stores.create(name="ib-bench-temp")
        for fid in file_ids:
            self.client.vector_stores.files.create(vector_store_id=vs.id, file_id=fid)
        # Wait for files to be processed
        print("  Waiting for vector store indexing...")
        while True:
            vs_status = self.client.vector_stores.retrieve(vs.id)
            if vs_status.file_counts.completed == len(file_ids):
                break
            if vs_status.file_counts.failed > 0:
                print(
                    f"  Warning: {vs_status.file_counts.failed} file(s) failed to index"
                )
                break
            time.sleep(1)
        return vs.id

    @retry_on_rate_limit(max_retries=3, initial_wait=60)
    def run(self, task: Task, input_files: list[Path] | None = None) -> LLMResponse:
        """Execute a task using Responses API with tools."""
        import base64

        start = time.time()
        files = input_files or []
        tools = []
        vector_store_id = None
        uploaded_file_ids = []

        # Separate files by type
        pdf_files = [f for f in files if f.suffix.lower() == ".pdf"]
        code_files = [f for f in files if f.suffix.lower() in [".xlsx", ".xls", ".csv"]]
        image_files = [
            f for f in files if f.suffix.lower() in [".png", ".jpg", ".jpeg"]
        ]

        # Upload PDFs and create vector store for file_search
        if pdf_files:
            print(f"  Uploading {len(pdf_files)} PDF(s) for file search...")
            pdf_file_ids = []
            for pdf in pdf_files:
                fid = self._upload_file(pdf)
                pdf_file_ids.append(fid)
                uploaded_file_ids.append(fid)
            vector_store_id = self._create_vector_store(pdf_file_ids)
            tools.append(
                {
                    "type": "file_search",
                    "vector_store_ids": [vector_store_id],
                }
            )

        # Upload Excel/CSV files for code_interpreter
        code_file_ids = []
        if code_files:
            print(f"  Uploading {len(code_files)} file(s) for code interpreter...")
            for cf in code_files:
                fid = self._upload_file(cf)
                code_file_ids.append(fid)
                uploaded_file_ids.append(fid)
            tools.append(
                {
                    "type": "code_interpreter",
                    "container": {"type": "auto", "file_ids": code_file_ids},
                }
            )

        # Build input content
        input_content = []

        # Add images as base64-encoded input
        for img in image_files:
            print(f"  Encoding {img.name} as base64...")
            with open(img, "rb") as f:
                img_data = base64.b64encode(f.read()).decode("utf-8")
            ext = img.suffix.lower().replace(".", "")
            mime = f"image/{ext}" if ext != "jpg" else "image/jpeg"
            input_content.append(
                {
                    "type": "input_image",
                    "image_url": {"url": f"data:{mime};base64,{img_data}"},
                }
            )

        # Add text prompt
        input_content.append(
            {
                "type": "input_text",
                "text": task.prompt,
            }
        )

        # Build the input - if just text, use simple string
        if len(input_content) == 1:
            api_input = task.prompt
        else:
            api_input = [{"role": "user", "content": input_content}]

        # Make API call with cleanup in finally block
        print("  Running Responses API...")
        content_filter_triggered = False
        try:
            response = self.client.responses.create(
                model=self.model,
                input=api_input,
                tools=tools if tools else None,
                temperature=0,  # Deterministic for reproducible evals
                max_output_tokens=16384,
            )
        except Exception as e:
            error_str = str(e).lower()
            # Check for content filter / policy violation errors
            # Note: "invalid prompt" has a space, not underscore
            if (
                "invalid_prompt" in error_str
                or "invalid prompt" in error_str
                or "flagged" in error_str
                or "usage policy" in error_str
            ):
                print(f"  BLOCKED: Content filter triggered")
                content_filter_triggered = True
                response = None
            else:
                raise
        finally:
            # Cleanup resources even if API call fails
            if vector_store_id:
                try:
                    self.client.vector_stores.delete(vector_store_id)
                except Exception as e:
                    print(f"  Warning: Failed to delete vector store: {e}")

            for fid in uploaded_file_ids:
                try:
                    self.client.files.delete(fid)
                except Exception as e:
                    print(f"  Warning: Failed to delete file {fid}: {e}")

        latency_ms = (time.time() - start) * 1000

        # Return early if content filter was triggered
        if content_filter_triggered:
            return LLMResponse(
                raw_text="",
                parsed_json=None,
                model=self.model,
                input_tokens=0,
                output_tokens=0,
                latency_ms=latency_ms,
                stop_reason="content_filter",
                output_files=None,
            )

        # Extract text from response
        response_text = response.output_text or ""

        # Extract file outputs from code_interpreter
        output_files = []
        if hasattr(response, "output") and response.output:
            for item in response.output:
                # Check for code_interpreter output with files
                if hasattr(item, "type") and item.type == "code_interpreter_call":
                    if hasattr(item, "outputs"):
                        for output in item.outputs:
                            if hasattr(output, "files"):
                                for f in output.files:
                                    try:
                                        print(f"  Downloading output file: {f.name}")
                                        file_content = self.client.files.content(
                                            f.file_id
                                        )
                                        output_files.append(
                                            OutputFile(
                                                filename=f.name,
                                                content=file_content.read()
                                                if hasattr(file_content, "read")
                                                else file_content,
                                                mime_type=getattr(
                                                    f,
                                                    "mime_type",
                                                    "application/octet-stream",
                                                ),
                                            )
                                        )
                                    except Exception as e:
                                        print(
                                            f"  Warning: Failed to download file {f.name}: {e}"
                                        )

        # Extract usage info
        usage = response.usage
        input_tokens = usage.input_tokens if usage else 0
        output_tokens = usage.output_tokens if usage else 0

        # Extract stop reason (Responses API uses status or stop_reason)
        stop_reason = getattr(response, "stop_reason", None) or "unknown"
        # Normalize: OpenAI uses "length" for max tokens
        if stop_reason == "length":
            stop_reason = "max_tokens"
            print(f"  WARNING: Output truncated (hit max_tokens limit)")

        parsed_json = _extract_json(response_text)

        return LLMResponse(
            raw_text=response_text.strip(),
            parsed_json=parsed_json,
            model=self.model,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            latency_ms=latency_ms,
            stop_reason=stop_reason,
            output_files=output_files if output_files else None,
        )


class GeminiRunner:
    """Run tasks against Google Gemini models using Files API + Code Execution."""

    def __init__(self, api_key: str | None = None, model: str | None = None):
        if not model:
            raise ValueError("model is required for GeminiRunner")
        self.api_key = (
            api_key
            or os.environ.get("GEMINI_API_KEY")
            or os.environ.get("GOOGLE_API_KEY")
        )
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY or GOOGLE_API_KEY not set")
        self.model = model
        self._client = None

    @property
    def client(self):
        if self._client is None:
            from google import genai

            self._client = genai.Client(api_key=self.api_key)
        return self._client

    def _upload_file(self, path: Path) -> object:
        """Upload file to Gemini Files API."""
        print(f"  Uploading {path.name} to Gemini Files API...")
        return self.client.files.upload(file=str(path))

    @retry_on_rate_limit(max_retries=3, initial_wait=60)
    def run(self, task: Task, input_files: list[Path] | None = None) -> LLMResponse:
        """Execute a task using Gemini with file upload and code execution."""
        from google.genai import types

        start = time.time()

        # Upload input files
        uploaded_files = []
        files_to_upload = input_files or []
        for f in files_to_upload:
            if f and f.exists():
                uploaded_file = self._upload_file(f)
                uploaded_files.append(uploaded_file)

        # Build contents with files and prompt
        contents = uploaded_files + [task.prompt]

        # Configure with code execution tool and deterministic settings
        config = types.GenerateContentConfig(
            tools=[types.Tool(code_execution=types.ToolCodeExecution)],
            temperature=0,  # Deterministic for reproducible evals
            max_output_tokens=16384,
        )

        # Make API call with cleanup in finally block
        print("  Running Gemini model...")
        content_filter_triggered = False
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=contents,
                config=config,
            )
        except Exception as e:
            error_str = str(e).lower()
            # Check for content filter / policy violation errors
            if "safety" in error_str or "blocked" in error_str or "policy" in error_str:
                print(f"  BLOCKED: Content filter triggered")
                content_filter_triggered = True
                response = None
            else:
                raise
        finally:
            # Cleanup uploaded files even if API call fails
            for uploaded_file in uploaded_files:
                try:
                    self.client.files.delete(name=uploaded_file.name)
                except Exception as e:
                    print(f"  Warning: Failed to delete file {uploaded_file.name}: {e}")

        latency_ms = (time.time() - start) * 1000

        # Return early if content filter was triggered by exception
        if content_filter_triggered:
            return LLMResponse(
                raw_text="",
                parsed_json=None,
                model=self.model,
                input_tokens=0,
                output_tokens=0,
                latency_ms=latency_ms,
                stop_reason="content_filter",
                output_files=None,
            )

        # Check for SAFETY finish_reason (another form of content filter)
        if response.candidates:
            finish_reason = getattr(response.candidates[0], "finish_reason", None)
            if finish_reason and "safety" in str(finish_reason).lower():
                print(
                    f"  BLOCKED: Content filter triggered (finish_reason={finish_reason})"
                )
                usage = response.usage_metadata
                return LLMResponse(
                    raw_text="",
                    parsed_json=None,
                    model=self.model,
                    input_tokens=usage.prompt_token_count if usage else 0,
                    output_tokens=0,
                    latency_ms=latency_ms,
                    stop_reason="content_filter",
                    output_files=None,
                )

        # Extract text and files from response parts (handle empty/blocked responses)
        response_text = ""
        output_files = []
        file_counter = 0

        if response.candidates and response.candidates[0].content:
            for part in response.candidates[0].content.parts:
                if hasattr(part, "text") and part.text is not None:
                    response_text += part.text + "\n"
                # Check for inline_data (files/images from code execution)
                if hasattr(part, "inline_data") and part.inline_data:
                    file_counter += 1
                    mime_type = getattr(
                        part.inline_data, "mime_type", "application/octet-stream"
                    )
                    # Generate filename based on mime type
                    ext = mime_type.split("/")[-1] if "/" in mime_type else "bin"
                    if ext == "vnd.openxmlformats-officedocument.spreadsheetml.sheet":
                        ext = "xlsx"
                    filename = f"output_{file_counter}.{ext}"
                    print(f"  Found output file: {filename} ({mime_type})")
                    output_files.append(
                        OutputFile(
                            filename=filename,
                            content=part.inline_data.data
                            if hasattr(part.inline_data, "data")
                            else b"",
                            mime_type=mime_type,
                        )
                    )

        # Extract usage info
        usage = response.usage_metadata
        input_tokens = usage.prompt_token_count if usage else 0
        output_tokens = usage.candidates_token_count if usage else 0

        # Extract stop reason (Gemini uses finish_reason: STOP, MAX_TOKENS, SAFETY, etc.)
        stop_reason = "unknown"
        if response.candidates:
            finish_reason = getattr(response.candidates[0], "finish_reason", None)
            if finish_reason:
                # Convert to string and normalize
                stop_reason = str(finish_reason).lower().replace("finishreason.", "")
                if stop_reason == "max_tokens":
                    print(f"  WARNING: Output truncated (hit max_tokens limit)")

        parsed_json = _extract_json(response_text)

        return LLMResponse(
            raw_text=response_text.strip(),
            parsed_json=parsed_json,
            model=self.model,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            latency_ms=latency_ms,
            stop_reason=stop_reason,
            output_files=output_files if output_files else None,
        )


def get_runner(provider: str, model: str):
    """Factory function to get the appropriate runner."""
    if provider == "anthropic":
        return AnthropicRunner(model=model)
    elif provider == "openai":
        return OpenAIRunner(model=model)
    elif provider == "gemini":
        return GeminiRunner(model=model)
    else:
        raise ValueError(f"Unknown provider: {provider}")


def create_run_directory(model: str, base_dir: Path | None = None) -> Path:
    """Create a timestamped run directory under responses/{model}/{run_id}."""
    if base_dir is None:
        base_dir = Path(__file__).parent / "responses"

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    # Sanitize model name for filesystem
    model_safe = model.replace("/", "-").replace(":", "-")
    run_dir = base_dir / model_safe / timestamp

    run_dir.mkdir(parents=True, exist_ok=True)

    return run_dir


class LLMJudge:
    """LLM-as-judge scorer using Claude with Files API."""

    def __init__(self, model: str = "claude-sonnet-4-5"):
        self.api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not set")
        self.model = model
        self._client = None

    @property
    def client(self):
        if self._client is None:
            import anthropic

            self._client = anthropic.Anthropic(api_key=self.api_key)
        return self._client

    def _parse_prose_scores(self, text: str, criteria_ids: list[str]) -> dict | None:
        """Fallback parser for prose format scores.

        Handles formats like:
        - "**summary_accuracy: 0.95/1.0**"
        - "Summary Accuracy: 0.85"
        - "summary accuracy: 0.9/1.0"
        - "1. summary_accuracy - 0.85"
        - "summary_accuracy**: 0.92/1.0"
        """
        scores = {}
        text_lower = text.lower()

        for cid in criteria_ids:
            # Try both underscore and space versions
            cid_variants = [
                cid.lower(),  # summary_accuracy
                cid.lower().replace("_", " "),  # summary accuracy
                cid.lower().replace("_", ""),  # summaryaccuracy
            ]

            found = False
            for cid_variant in cid_variants:
                if found:
                    break
                # Try multiple patterns
                patterns = [
                    rf"\*?\*?{re.escape(cid_variant)}\*?\*?[:\s]+(\d+\.?\d*)\s*/\s*1\.?0?",  # "accuracy: 0.95/1.0"
                    rf"\*?\*?{re.escape(cid_variant)}\*?\*?[:\s]+(\d+\.?\d*)(?:/|\s|$)",  # "accuracy: 0.85"
                    rf"{re.escape(cid_variant)}[:\-\s]+(\d+\.?\d*)",  # "accuracy - 0.85"
                    rf"{re.escape(cid_variant)}[^0-9]*(\d+\.?\d*)\s*/\s*1",  # "accuracy**: 0.92/1"
                ]

                for pattern in patterns:
                    match = re.search(pattern, text_lower)
                    if match:
                        try:
                            score_val = float(match.group(1))
                            # Normalize if > 1 (e.g., 95 -> 0.95)
                            if score_val > 1:
                                score_val = score_val / 100
                            scores[cid] = {
                                "score": min(score_val, 1.0),
                                "reasoning": "Parsed from prose",
                            }
                            found = True
                            break
                        except ValueError:
                            continue

        if scores:
            return {"scores": scores}
        return None

    @retry_on_rate_limit(max_retries=3, initial_wait=60)
    def _call_api(self, content: list) -> object:
        """Make the API call with retry logic for rate limits."""
        return self.client.beta.messages.create(
            model=self.model,
            betas=["code-execution-2025-08-25", "files-api-2025-04-14"],
            max_tokens=16384,
            temperature=0,  # Deterministic for consistent judging
            messages=[{"role": "user", "content": content}],
            tools=[{"type": "code_execution_20250825", "name": "code_execution"}],
        )

    def score(self, rubric: dict, source_files: list[Path], response_text: str) -> dict:
        """Score a response against rubric criteria.

        Args:
            rubric: Rubric dict with criteria list
            source_files: List of source documents (PDF, xlsx, etc.)
            response_text: The response text to evaluate

        Returns:
            {
                "scores": {
                    "criterion_id": {"score": 0.0-1.0, "reasoning": "..."},
                    ...
                },
                "weighted_total": 0.85
            }
        """
        criteria = rubric.get("criteria", {})
        criteria_text = "\n".join(
            f"- **{cid}** ({spec.get('points', 0)} points): {spec['description']}"
            for cid, spec in criteria.items()
        )

        file_objects = []
        file_names = [f.name for f in source_files]
        print(f"  Uploading {len(source_files)} file(s) to Files API for judging...")
        for source_file in source_files:
            with open(source_file, "rb") as f:
                file_obj = self.client.beta.files.upload(file=f)
                file_objects.append(file_obj)

        criteria_ids = list(criteria.keys())
        files_list = ", ".join(file_names)
        judge_prompt = f"""You are an expert evaluator for investment banking work products.

## Source Documents
{files_list}

## Response to Evaluate
{response_text}

## Evaluation Criteria
{criteria_text}

## Output Requirements
- Score each criterion 0-1 (0=fails, 1=perfect)
- Output ONLY valid JSON, nothing else
- Do NOT print analysis, thinking, or explanations outside JSON
- Do NOT use code execution to explore files - just read and score

```json
{{
  "scores": {{
    "{criteria_ids[0]}": {{"score": 0.85, "reasoning": "brief reason"}},
    ...include all: {criteria_ids}
  }}
}}
```"""

        content = [
            {"type": "container_upload", "file_id": fo.id} for fo in file_objects
        ]
        content.append({"type": "text", "text": judge_prompt})

        start = time.time()
        try:
            response = self._call_api(content)
        finally:
            for fo in file_objects:
                try:
                    self.client.beta.files.delete(fo.id)
                except Exception as e:
                    print(f"  Warning: Failed to delete judge file {fo.id}: {e}")

        latency_ms = (time.time() - start) * 1000
        print(f"  Judge completed in {latency_ms:.0f}ms")

        # Extract text from response - include both text blocks and code execution stdout
        text_blocks = []
        for block in response.content:
            if hasattr(block, "text") and block.text:
                text_blocks.append(block.text)
            # Also extract stdout from code execution results
            if hasattr(block, "type") and block.type == "code_execution_result":
                if hasattr(block, "content"):
                    for item in block.content:
                        if hasattr(item, "stdout") and item.stdout:
                            text_blocks.append(item.stdout)
                        elif hasattr(item, "text") and item.text:
                            text_blocks.append(item.text)

        # Try to find JSON in text blocks first (most likely location for scores)
        raw_text = ""
        for text in text_blocks:
            if '{"scores"' in text or '"scores":' in text:
                # This block likely contains our JSON - use it directly
                raw_text = text
                break

        # Fallback: concatenate all text blocks
        if not raw_text:
            raw_text = "\n".join(text_blocks)

        # Parse JSON from response
        parsed = _extract_json(raw_text)
        if not parsed or not parsed.get("scores"):
            # Fallback: try to parse prose format like "**accuracy: 0.95/1.0**"
            print("  Warning: JSON parse failed, trying prose fallback...")
            parsed = self._parse_prose_scores(raw_text, criteria_ids)
            if not parsed:
                print("  Warning: Could not parse judge response")
                print(f"  Preview: {raw_text[:200] if raw_text else '(empty)'}...")
                return {"scores": {}, "weighted_total": 0.0, "raw_response": raw_text}

        # Calculate weighted total
        scores = parsed.get("scores", {})
        weighted_total = 0.0
        total_weight = 0.0

        for cid, criterion in criteria.items():
            points = criterion.get("points", 0)
            if cid in scores:
                score_val = scores[cid].get("score", 0)
                weighted_total += score_val * points
                total_weight += points

        # Normalize to 0-1 scale if weights don't sum to 1
        if total_weight > 0:
            weighted_total = weighted_total / total_weight

        parsed["weighted_total"] = weighted_total
        return parsed
