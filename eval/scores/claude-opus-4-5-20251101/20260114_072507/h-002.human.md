# Human Scoring Template: h-002

## Files
- Score JSON: h-002.json
- Response JSON: /Users/da1m/Code/ib-bench/eval/responses/claude-opus-4-5-20251101/20260114_072507/h-002.json
- Prompt: /Users/da1m/Code/ib-bench/eval/tasks/h-002/prompt.md
- Inputs: input.xlsx

## How to Score
- Open the score JSON file and fill in `score` (0-1) and `reasoning` for each criterion.
- Use the scoring guide below as the anchor for your judgment.

## Criteria
### historical_updates (20 pts)
Description: Historical inputs are populated correctly for the last three fiscal years with credible sourcing
Scoring guide: 1.0 = correct and complete historicals with sources; 0.5 = partial or minor errors; 0 = missing/incorrect

### assumptions_summary (15 pts)
Description: Entry, leverage, and projection assumptions are reasonable and internally consistent
Scoring guide: 1.0 = clear, defensible assumptions; 0.5 = partially reasonable; 0 = unrealistic or missing

### returns_summary (15 pts)
Description: Returns analysis (IRR/MOIC) and exit assumptions are coherent and supported by the model
Scoring guide: 1.0 = returns computed and consistent; 0.5 = partial or inconsistent; 0 = missing/incorrect

### business_assessment (25 pts)
Description: Business assessment covers market position, strengths/weaknesses, risks, and competitive landscape
Scoring guide: 1.0 = thorough, specific assessment; 0.5 = surface-level; 0 = missing/irrelevant

### recommendation (10 pts)
Description: Go/No-Go recommendation is clear and supported by rationale and next steps
Scoring guide: 1.0 = clear decision with rationale; 0.5 = vague; 0 = missing

### model_integrity_checks (10 pts)
Description: Model ties and reconciliation checks are validated after updates
Scoring guide: 1.0 = checks explicitly confirmed; 0.5 = partial checks; 0 = no validation

### formatting (5 pts)
Description: IB formatting conventions and existing model style are followed for modified cells
Scoring guide: 1.0 = formatting consistent and correct; 0.5 = minor issues; 0 = incorrect formatting
